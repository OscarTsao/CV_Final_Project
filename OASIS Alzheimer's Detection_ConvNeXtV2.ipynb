{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download OASIS DATASet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.5)\n",
      "Path to dataset files: /home/lab308/.cache/kagglehub/datasets/ninadaithal/imagesoasis/versions/1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ninadaithal/imagesoasis\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from PIL import Image\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "Data_size: 224 x 224\n",
    "1. Non demented: 6,7222\n",
    "2. mild demented: 5002\n",
    "3. moderate demented: 488\n",
    "4. very demented: 1,3725"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "from dataset import BasicDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(size=(224, 224)),  # resize to 224x224\n",
    "    transforms.ToTensor(),          # convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )  # standard ImageNet normalization\n",
    "])\n",
    "\n",
    "preprocessor = AutoImageProcessor.from_pretrained(\"facebook/convnextv2-base-22k-224\")\n",
    "\n",
    "# import dataset\n",
    "from dataset import BasicDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.CenterCrop(size=(224, 224)),  # resize to 224x224\n",
    "    transforms.ToTensor(),          # convert PIL image to PyTorch tensor\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )  # standard ImageNet normalization\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root='data/train', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "total_size = len(train_dataset)\n",
    "train_size = int(0.8 * total_size)\n",
    "val_size = total_size - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
    "finetune_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "imagenet_loader = datasets.ImageNet(root='data/imagenet', split='train', transform=transform)\n",
    "imagenet_loader = DataLoader(imagenet_loader, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch shape: torch.Size([8, 3, 224, 224])\n",
      "Label batch shape: torch.Size([8])\n",
      "Labels: tensor([2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(\"Image batch shape:\", images.shape)\n",
    "print(\"Label batch shape:\", labels.shape)\n",
    "print(\"Labels:\", labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pre-trained checkpoint from: Model/ConvNeXtV2/pretrained/convnextv2_base_22k_224_ema.pt\n",
      "Removing key head.weight from pretrained checkpoint\n",
      "Removing key head.bias from pretrained checkpoint\n"
     ]
    }
   ],
   "source": [
    "# Model settings\n",
    "from Model.ConvNeXtV2.convnextv2 import convnextv2_base as autoencoder\n",
    "from Model.ConvNeXtV2.fcmae import convnextv2_base as mae\n",
    "from timm.optim import optim_factory\n",
    "from timm.models.layers import trunc_normal_\n",
    "\n",
    "weight_path = os.path.join(\"Model\", \"ConvNeXtV2\", \"pretrained\", \"convnextv2_base_22k_224_ema.pt\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_mae = mae()\n",
    "\n",
    "checkpoint = torch.load(weight_path, map_location='cpu')\n",
    "\n",
    "print(\"Load pre-trained checkpoint from: %s\" % weight_path)\n",
    "checkpoint_model = checkpoint['model']\n",
    "for k in ['head.weight', 'head.bias']:\n",
    "    if k in checkpoint_model :\n",
    "        print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "        del checkpoint_model[k]\n",
    "        \n",
    "#model_mae.load_state_dict(checkpoint_model, strict=False)\n",
    "\n",
    "\n",
    "model_autoencoder = autoencoder(num_classes=4)\n",
    "model_autoencoder.load_state_dict(checkpoint_model, strict=False)\n",
    "# manually initialize fc layer\n",
    "trunc_normal_(model_autoencoder.head.weight, std=2e-5)\n",
    "torch.nn.init.constant_(model_autoencoder.head.bias, 0.)\n",
    "\n",
    "param_groups = optim_factory.add_weight_decay(model_mae, 0.05)\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=1.5e-4, betas=(0.9, 0.95))\n",
    "\n",
    "model_mae = model_mae.to(device)\n",
    "model_autoencoder = model_autoencoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_token: -0.0004080507787875831\n",
      "encoder.downsample_layers.0.0.weight: -0.015571651980280876\n",
      "encoder.downsample_layers.0.0.bias: 0.0\n",
      "encoder.downsample_layers.0.1.weight: 1.0\n",
      "encoder.downsample_layers.0.1.bias: 0.0\n",
      "encoder.downsample_layers.1.0.ln.weight: 1.0\n",
      "encoder.downsample_layers.1.0.ln.bias: 0.0\n",
      "encoder.downsample_layers.1.1.kernel: -5.830774534842931e-05\n",
      "encoder.downsample_layers.1.1.bias: 0.0\n",
      "encoder.downsample_layers.2.0.ln.weight: 1.0\n",
      "encoder.downsample_layers.2.0.ln.bias: 0.0\n",
      "encoder.downsample_layers.2.1.kernel: -6.119896625023102e-06\n",
      "encoder.downsample_layers.2.1.bias: 0.0\n",
      "encoder.downsample_layers.3.0.ln.weight: 1.0\n",
      "encoder.downsample_layers.3.0.ln.bias: 0.0\n",
      "encoder.downsample_layers.3.1.kernel: -2.589037194411503e-06\n",
      "encoder.downsample_layers.3.1.bias: 0.0\n",
      "encoder.stages.0.0.dwconv.kernel: -0.01506991870701313\n",
      "encoder.stages.0.0.dwconv.bias: 0.0\n",
      "encoder.stages.0.0.norm.ln.weight: 1.0\n",
      "encoder.stages.0.0.norm.ln.bias: 0.0\n",
      "encoder.stages.0.0.pwconv1.linear.weight: -0.00409198272973299\n",
      "encoder.stages.0.0.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.0.0.pwconv2.linear.weight: -0.0010489998385310173\n",
      "encoder.stages.0.0.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.0.0.grn.gamma: 0.0\n",
      "encoder.stages.0.0.grn.beta: 0.0\n",
      "encoder.stages.0.1.dwconv.kernel: -0.019449761137366295\n",
      "encoder.stages.0.1.dwconv.bias: 0.0\n",
      "encoder.stages.0.1.norm.ln.weight: 1.0\n",
      "encoder.stages.0.1.norm.ln.bias: 0.0\n",
      "encoder.stages.0.1.pwconv1.linear.weight: -0.00030042405705899\n",
      "encoder.stages.0.1.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.0.1.pwconv2.linear.weight: 0.003425969509407878\n",
      "encoder.stages.0.1.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.0.1.grn.gamma: 0.0\n",
      "encoder.stages.0.1.grn.beta: 0.0\n",
      "encoder.stages.0.2.dwconv.kernel: -0.002907190239056945\n",
      "encoder.stages.0.2.dwconv.bias: 0.0\n",
      "encoder.stages.0.2.norm.ln.weight: 1.0\n",
      "encoder.stages.0.2.norm.ln.bias: 0.0\n",
      "encoder.stages.0.2.pwconv1.linear.weight: 0.0005063263233751059\n",
      "encoder.stages.0.2.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.0.2.pwconv2.linear.weight: -0.0010069382842630148\n",
      "encoder.stages.0.2.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.0.2.grn.gamma: 0.0\n",
      "encoder.stages.0.2.grn.beta: 0.0\n",
      "encoder.stages.1.0.dwconv.kernel: 0.004824168048799038\n",
      "encoder.stages.1.0.dwconv.bias: 0.0\n",
      "encoder.stages.1.0.norm.ln.weight: 1.0\n",
      "encoder.stages.1.0.norm.ln.bias: 0.0\n",
      "encoder.stages.1.0.pwconv1.linear.weight: -0.0004469839041121304\n",
      "encoder.stages.1.0.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.1.0.pwconv2.linear.weight: -0.002230070298537612\n",
      "encoder.stages.1.0.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.1.0.grn.gamma: 0.0\n",
      "encoder.stages.1.0.grn.beta: 0.0\n",
      "encoder.stages.1.1.dwconv.kernel: 0.005299803335219622\n",
      "encoder.stages.1.1.dwconv.bias: 0.0\n",
      "encoder.stages.1.1.norm.ln.weight: 1.0\n",
      "encoder.stages.1.1.norm.ln.bias: 0.0\n",
      "encoder.stages.1.1.pwconv1.linear.weight: 0.0007527746492996812\n",
      "encoder.stages.1.1.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.1.1.pwconv2.linear.weight: -0.00240087928250432\n",
      "encoder.stages.1.1.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.1.1.grn.gamma: 0.0\n",
      "encoder.stages.1.1.grn.beta: 0.0\n",
      "encoder.stages.1.2.dwconv.kernel: -0.0003056587011087686\n",
      "encoder.stages.1.2.dwconv.bias: 0.0\n",
      "encoder.stages.1.2.norm.ln.weight: 1.0\n",
      "encoder.stages.1.2.norm.ln.bias: 0.0\n",
      "encoder.stages.1.2.pwconv1.linear.weight: 0.002708614803850651\n",
      "encoder.stages.1.2.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.1.2.pwconv2.linear.weight: -0.0011615107068791986\n",
      "encoder.stages.1.2.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.1.2.grn.gamma: 0.0\n",
      "encoder.stages.1.2.grn.beta: 0.0\n",
      "encoder.stages.2.0.dwconv.kernel: 0.002316870028153062\n",
      "encoder.stages.2.0.dwconv.bias: 0.0\n",
      "encoder.stages.2.0.norm.ln.weight: 1.0\n",
      "encoder.stages.2.0.norm.ln.bias: 0.0\n",
      "encoder.stages.2.0.pwconv1.linear.weight: -0.0002584802859928459\n",
      "encoder.stages.2.0.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.0.pwconv2.linear.weight: 0.0002729088591877371\n",
      "encoder.stages.2.0.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.0.grn.gamma: 0.0\n",
      "encoder.stages.2.0.grn.beta: 0.0\n",
      "encoder.stages.2.1.dwconv.kernel: 0.0013136104680597782\n",
      "encoder.stages.2.1.dwconv.bias: 0.0\n",
      "encoder.stages.2.1.norm.ln.weight: 1.0\n",
      "encoder.stages.2.1.norm.ln.bias: 0.0\n",
      "encoder.stages.2.1.pwconv1.linear.weight: -0.0008535217493772507\n",
      "encoder.stages.2.1.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.1.pwconv2.linear.weight: 0.000701452256180346\n",
      "encoder.stages.2.1.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.1.grn.gamma: 0.0\n",
      "encoder.stages.2.1.grn.beta: 0.0\n",
      "encoder.stages.2.2.dwconv.kernel: 0.004964472725987434\n",
      "encoder.stages.2.2.dwconv.bias: 0.0\n",
      "encoder.stages.2.2.norm.ln.weight: 1.0\n",
      "encoder.stages.2.2.norm.ln.bias: 0.0\n",
      "encoder.stages.2.2.pwconv1.linear.weight: 5.4162461310625076e-05\n",
      "encoder.stages.2.2.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.2.pwconv2.linear.weight: -0.00031744904117658734\n",
      "encoder.stages.2.2.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.2.grn.gamma: 0.0\n",
      "encoder.stages.2.2.grn.beta: 0.0\n",
      "encoder.stages.2.3.dwconv.kernel: 0.000334896583808586\n",
      "encoder.stages.2.3.dwconv.bias: 0.0\n",
      "encoder.stages.2.3.norm.ln.weight: 1.0\n",
      "encoder.stages.2.3.norm.ln.bias: 0.0\n",
      "encoder.stages.2.3.pwconv1.linear.weight: 0.0004197056114207953\n",
      "encoder.stages.2.3.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.3.pwconv2.linear.weight: -0.0009099245653487742\n",
      "encoder.stages.2.3.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.3.grn.gamma: 0.0\n",
      "encoder.stages.2.3.grn.beta: 0.0\n",
      "encoder.stages.2.4.dwconv.kernel: -0.0030929057393223047\n",
      "encoder.stages.2.4.dwconv.bias: 0.0\n",
      "encoder.stages.2.4.norm.ln.weight: 1.0\n",
      "encoder.stages.2.4.norm.ln.bias: 0.0\n",
      "encoder.stages.2.4.pwconv1.linear.weight: 0.00042989442590624094\n",
      "encoder.stages.2.4.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.4.pwconv2.linear.weight: -0.001570798922330141\n",
      "encoder.stages.2.4.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.4.grn.gamma: 0.0\n",
      "encoder.stages.2.4.grn.beta: 0.0\n",
      "encoder.stages.2.5.dwconv.kernel: -0.0007893069414421916\n",
      "encoder.stages.2.5.dwconv.bias: 0.0\n",
      "encoder.stages.2.5.norm.ln.weight: 1.0\n",
      "encoder.stages.2.5.norm.ln.bias: 0.0\n",
      "encoder.stages.2.5.pwconv1.linear.weight: 0.0001201080740429461\n",
      "encoder.stages.2.5.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.5.pwconv2.linear.weight: -0.0008110509952530265\n",
      "encoder.stages.2.5.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.5.grn.gamma: 0.0\n",
      "encoder.stages.2.5.grn.beta: 0.0\n",
      "encoder.stages.2.6.dwconv.kernel: -0.002355135278776288\n",
      "encoder.stages.2.6.dwconv.bias: 0.0\n",
      "encoder.stages.2.6.norm.ln.weight: 1.0\n",
      "encoder.stages.2.6.norm.ln.bias: 0.0\n",
      "encoder.stages.2.6.pwconv1.linear.weight: 0.002050482202321291\n",
      "encoder.stages.2.6.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.6.pwconv2.linear.weight: 0.00029204710153862834\n",
      "encoder.stages.2.6.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.6.grn.gamma: 0.0\n",
      "encoder.stages.2.6.grn.beta: 0.0\n",
      "encoder.stages.2.7.dwconv.kernel: -0.0018563255434855819\n",
      "encoder.stages.2.7.dwconv.bias: 0.0\n",
      "encoder.stages.2.7.norm.ln.weight: 1.0\n",
      "encoder.stages.2.7.norm.ln.bias: 0.0\n",
      "encoder.stages.2.7.pwconv1.linear.weight: -0.00040318016544915736\n",
      "encoder.stages.2.7.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.7.pwconv2.linear.weight: 0.00015349662862718105\n",
      "encoder.stages.2.7.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.7.grn.gamma: 0.0\n",
      "encoder.stages.2.7.grn.beta: 0.0\n",
      "encoder.stages.2.8.dwconv.kernel: -0.00449487054720521\n",
      "encoder.stages.2.8.dwconv.bias: 0.0\n",
      "encoder.stages.2.8.norm.ln.weight: 1.0\n",
      "encoder.stages.2.8.norm.ln.bias: 0.0\n",
      "encoder.stages.2.8.pwconv1.linear.weight: 0.00035823031794279814\n",
      "encoder.stages.2.8.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.8.pwconv2.linear.weight: -0.001283368095755577\n",
      "encoder.stages.2.8.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.8.grn.gamma: 0.0\n",
      "encoder.stages.2.8.grn.beta: 0.0\n",
      "encoder.stages.2.9.dwconv.kernel: -0.0007053244626149535\n",
      "encoder.stages.2.9.dwconv.bias: 0.0\n",
      "encoder.stages.2.9.norm.ln.weight: 1.0\n",
      "encoder.stages.2.9.norm.ln.bias: 0.0\n",
      "encoder.stages.2.9.pwconv1.linear.weight: 0.00025490112602710724\n",
      "encoder.stages.2.9.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.9.pwconv2.linear.weight: 0.0013658327516168356\n",
      "encoder.stages.2.9.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.9.grn.gamma: 0.0\n",
      "encoder.stages.2.9.grn.beta: 0.0\n",
      "encoder.stages.2.10.dwconv.kernel: 0.0035068714059889317\n",
      "encoder.stages.2.10.dwconv.bias: 0.0\n",
      "encoder.stages.2.10.norm.ln.weight: 1.0\n",
      "encoder.stages.2.10.norm.ln.bias: 0.0\n",
      "encoder.stages.2.10.pwconv1.linear.weight: -0.0014577459078282118\n",
      "encoder.stages.2.10.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.10.pwconv2.linear.weight: -0.0006008079508319497\n",
      "encoder.stages.2.10.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.10.grn.gamma: 0.0\n",
      "encoder.stages.2.10.grn.beta: 0.0\n",
      "encoder.stages.2.11.dwconv.kernel: -0.004230555146932602\n",
      "encoder.stages.2.11.dwconv.bias: 0.0\n",
      "encoder.stages.2.11.norm.ln.weight: 1.0\n",
      "encoder.stages.2.11.norm.ln.bias: 0.0\n",
      "encoder.stages.2.11.pwconv1.linear.weight: -0.0007307117921300232\n",
      "encoder.stages.2.11.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.11.pwconv2.linear.weight: 0.0005143401212990284\n",
      "encoder.stages.2.11.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.11.grn.gamma: 0.0\n",
      "encoder.stages.2.11.grn.beta: 0.0\n",
      "encoder.stages.2.12.dwconv.kernel: -0.0025508846156299114\n",
      "encoder.stages.2.12.dwconv.bias: 0.0\n",
      "encoder.stages.2.12.norm.ln.weight: 1.0\n",
      "encoder.stages.2.12.norm.ln.bias: 0.0\n",
      "encoder.stages.2.12.pwconv1.linear.weight: 0.00035592756466940045\n",
      "encoder.stages.2.12.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.12.pwconv2.linear.weight: -0.0009543822379782796\n",
      "encoder.stages.2.12.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.12.grn.gamma: 0.0\n",
      "encoder.stages.2.12.grn.beta: 0.0\n",
      "encoder.stages.2.13.dwconv.kernel: 0.0026181295979768038\n",
      "encoder.stages.2.13.dwconv.bias: 0.0\n",
      "encoder.stages.2.13.norm.ln.weight: 1.0\n",
      "encoder.stages.2.13.norm.ln.bias: 0.0\n",
      "encoder.stages.2.13.pwconv1.linear.weight: -0.0009628452826291323\n",
      "encoder.stages.2.13.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.13.pwconv2.linear.weight: 3.583019133657217e-05\n",
      "encoder.stages.2.13.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.13.grn.gamma: 0.0\n",
      "encoder.stages.2.13.grn.beta: 0.0\n",
      "encoder.stages.2.14.dwconv.kernel: 0.0010953914606943727\n",
      "encoder.stages.2.14.dwconv.bias: 0.0\n",
      "encoder.stages.2.14.norm.ln.weight: 1.0\n",
      "encoder.stages.2.14.norm.ln.bias: 0.0\n",
      "encoder.stages.2.14.pwconv1.linear.weight: 0.00046285800635814667\n",
      "encoder.stages.2.14.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.14.pwconv2.linear.weight: 1.7412123270332813e-05\n",
      "encoder.stages.2.14.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.14.grn.gamma: 0.0\n",
      "encoder.stages.2.14.grn.beta: 0.0\n",
      "encoder.stages.2.15.dwconv.kernel: -0.0016154272016137838\n",
      "encoder.stages.2.15.dwconv.bias: 0.0\n",
      "encoder.stages.2.15.norm.ln.weight: 1.0\n",
      "encoder.stages.2.15.norm.ln.bias: 0.0\n",
      "encoder.stages.2.15.pwconv1.linear.weight: 0.001520039513707161\n",
      "encoder.stages.2.15.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.15.pwconv2.linear.weight: -0.0008109854534268379\n",
      "encoder.stages.2.15.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.15.grn.gamma: 0.0\n",
      "encoder.stages.2.15.grn.beta: 0.0\n",
      "encoder.stages.2.16.dwconv.kernel: 0.0064329407177865505\n",
      "encoder.stages.2.16.dwconv.bias: 0.0\n",
      "encoder.stages.2.16.norm.ln.weight: 1.0\n",
      "encoder.stages.2.16.norm.ln.bias: 0.0\n",
      "encoder.stages.2.16.pwconv1.linear.weight: -0.00014335429295897484\n",
      "encoder.stages.2.16.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.16.pwconv2.linear.weight: -0.00035660172579810023\n",
      "encoder.stages.2.16.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.16.grn.gamma: 0.0\n",
      "encoder.stages.2.16.grn.beta: 0.0\n",
      "encoder.stages.2.17.dwconv.kernel: 0.0038250009529292583\n",
      "encoder.stages.2.17.dwconv.bias: 0.0\n",
      "encoder.stages.2.17.norm.ln.weight: 1.0\n",
      "encoder.stages.2.17.norm.ln.bias: 0.0\n",
      "encoder.stages.2.17.pwconv1.linear.weight: 0.0008217787835747004\n",
      "encoder.stages.2.17.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.17.pwconv2.linear.weight: 8.089659968391061e-05\n",
      "encoder.stages.2.17.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.17.grn.gamma: 0.0\n",
      "encoder.stages.2.17.grn.beta: 0.0\n",
      "encoder.stages.2.18.dwconv.kernel: 0.0031056422740221024\n",
      "encoder.stages.2.18.dwconv.bias: 0.0\n",
      "encoder.stages.2.18.norm.ln.weight: 1.0\n",
      "encoder.stages.2.18.norm.ln.bias: 0.0\n",
      "encoder.stages.2.18.pwconv1.linear.weight: 0.0011285778600722551\n",
      "encoder.stages.2.18.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.18.pwconv2.linear.weight: 0.0018493204843252897\n",
      "encoder.stages.2.18.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.18.grn.gamma: 0.0\n",
      "encoder.stages.2.18.grn.beta: 0.0\n",
      "encoder.stages.2.19.dwconv.kernel: -0.010867103934288025\n",
      "encoder.stages.2.19.dwconv.bias: 0.0\n",
      "encoder.stages.2.19.norm.ln.weight: 1.0\n",
      "encoder.stages.2.19.norm.ln.bias: 0.0\n",
      "encoder.stages.2.19.pwconv1.linear.weight: -0.0003483026521280408\n",
      "encoder.stages.2.19.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.19.pwconv2.linear.weight: -0.0007031867280602455\n",
      "encoder.stages.2.19.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.19.grn.gamma: 0.0\n",
      "encoder.stages.2.19.grn.beta: 0.0\n",
      "encoder.stages.2.20.dwconv.kernel: 0.006526704411953688\n",
      "encoder.stages.2.20.dwconv.bias: 0.0\n",
      "encoder.stages.2.20.norm.ln.weight: 1.0\n",
      "encoder.stages.2.20.norm.ln.bias: 0.0\n",
      "encoder.stages.2.20.pwconv1.linear.weight: 0.0010665387380868196\n",
      "encoder.stages.2.20.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.20.pwconv2.linear.weight: 0.0005236939759925008\n",
      "encoder.stages.2.20.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.20.grn.gamma: 0.0\n",
      "encoder.stages.2.20.grn.beta: 0.0\n",
      "encoder.stages.2.21.dwconv.kernel: -0.009832453913986683\n",
      "encoder.stages.2.21.dwconv.bias: 0.0\n",
      "encoder.stages.2.21.norm.ln.weight: 1.0\n",
      "encoder.stages.2.21.norm.ln.bias: 0.0\n",
      "encoder.stages.2.21.pwconv1.linear.weight: -0.0012665926478803158\n",
      "encoder.stages.2.21.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.21.pwconv2.linear.weight: -0.00016591418534517288\n",
      "encoder.stages.2.21.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.21.grn.gamma: 0.0\n",
      "encoder.stages.2.21.grn.beta: 0.0\n",
      "encoder.stages.2.22.dwconv.kernel: 0.0025444193743169308\n",
      "encoder.stages.2.22.dwconv.bias: 0.0\n",
      "encoder.stages.2.22.norm.ln.weight: 1.0\n",
      "encoder.stages.2.22.norm.ln.bias: 0.0\n",
      "encoder.stages.2.22.pwconv1.linear.weight: -0.0002984031452797353\n",
      "encoder.stages.2.22.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.22.pwconv2.linear.weight: -0.0012657037004828453\n",
      "encoder.stages.2.22.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.22.grn.gamma: 0.0\n",
      "encoder.stages.2.22.grn.beta: 0.0\n",
      "encoder.stages.2.23.dwconv.kernel: 0.008240284398198128\n",
      "encoder.stages.2.23.dwconv.bias: 0.0\n",
      "encoder.stages.2.23.norm.ln.weight: 1.0\n",
      "encoder.stages.2.23.norm.ln.bias: 0.0\n",
      "encoder.stages.2.23.pwconv1.linear.weight: -0.00026582402642816305\n",
      "encoder.stages.2.23.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.23.pwconv2.linear.weight: 0.00012428712216205895\n",
      "encoder.stages.2.23.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.23.grn.gamma: 0.0\n",
      "encoder.stages.2.23.grn.beta: 0.0\n",
      "encoder.stages.2.24.dwconv.kernel: 0.009464521892368793\n",
      "encoder.stages.2.24.dwconv.bias: 0.0\n",
      "encoder.stages.2.24.norm.ln.weight: 1.0\n",
      "encoder.stages.2.24.norm.ln.bias: 0.0\n",
      "encoder.stages.2.24.pwconv1.linear.weight: -0.00014642401947639883\n",
      "encoder.stages.2.24.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.24.pwconv2.linear.weight: 0.00039658710011281073\n",
      "encoder.stages.2.24.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.24.grn.gamma: 0.0\n",
      "encoder.stages.2.24.grn.beta: 0.0\n",
      "encoder.stages.2.25.dwconv.kernel: -0.0007609045132994652\n",
      "encoder.stages.2.25.dwconv.bias: 0.0\n",
      "encoder.stages.2.25.norm.ln.weight: 1.0\n",
      "encoder.stages.2.25.norm.ln.bias: 0.0\n",
      "encoder.stages.2.25.pwconv1.linear.weight: 0.0007973440224304795\n",
      "encoder.stages.2.25.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.25.pwconv2.linear.weight: -0.0005613430985249579\n",
      "encoder.stages.2.25.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.25.grn.gamma: 0.0\n",
      "encoder.stages.2.25.grn.beta: 0.0\n",
      "encoder.stages.2.26.dwconv.kernel: -0.006987166590988636\n",
      "encoder.stages.2.26.dwconv.bias: 0.0\n",
      "encoder.stages.2.26.norm.ln.weight: 1.0\n",
      "encoder.stages.2.26.norm.ln.bias: 0.0\n",
      "encoder.stages.2.26.pwconv1.linear.weight: 0.0006609013071283698\n",
      "encoder.stages.2.26.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.2.26.pwconv2.linear.weight: 0.000720204203389585\n",
      "encoder.stages.2.26.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.2.26.grn.gamma: 0.0\n",
      "encoder.stages.2.26.grn.beta: 0.0\n",
      "encoder.stages.3.0.dwconv.kernel: 0.0029274586122483015\n",
      "encoder.stages.3.0.dwconv.bias: 0.0\n",
      "encoder.stages.3.0.norm.ln.weight: 1.0\n",
      "encoder.stages.3.0.norm.ln.bias: 0.0\n",
      "encoder.stages.3.0.pwconv1.linear.weight: 0.00011240920866839588\n",
      "encoder.stages.3.0.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.3.0.pwconv2.linear.weight: 0.00014104216825217009\n",
      "encoder.stages.3.0.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.3.0.grn.gamma: 0.0\n",
      "encoder.stages.3.0.grn.beta: 0.0\n",
      "encoder.stages.3.1.dwconv.kernel: -0.00341684278100729\n",
      "encoder.stages.3.1.dwconv.bias: 0.0\n",
      "encoder.stages.3.1.norm.ln.weight: 1.0\n",
      "encoder.stages.3.1.norm.ln.bias: 0.0\n",
      "encoder.stages.3.1.pwconv1.linear.weight: -0.0008317397441715002\n",
      "encoder.stages.3.1.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.3.1.pwconv2.linear.weight: 0.0001603542477823794\n",
      "encoder.stages.3.1.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.3.1.grn.gamma: 0.0\n",
      "encoder.stages.3.1.grn.beta: 0.0\n",
      "encoder.stages.3.2.dwconv.kernel: -0.000987119390629232\n",
      "encoder.stages.3.2.dwconv.bias: 0.0\n",
      "encoder.stages.3.2.norm.ln.weight: 1.0\n",
      "encoder.stages.3.2.norm.ln.bias: 0.0\n",
      "encoder.stages.3.2.pwconv1.linear.weight: -0.00028028766973875463\n",
      "encoder.stages.3.2.pwconv1.linear.bias: 0.0\n",
      "encoder.stages.3.2.pwconv2.linear.weight: 3.267190186306834e-05\n",
      "encoder.stages.3.2.pwconv2.linear.bias: 0.0\n",
      "encoder.stages.3.2.grn.gamma: 0.0\n",
      "encoder.stages.3.2.grn.beta: 0.0\n",
      "proj.weight: -0.001420102547854185\n",
      "proj.bias: 0.0\n",
      "decoder.0.dwconv.weight: 5.338751361705363e-05\n",
      "decoder.0.dwconv.bias: 0.0\n",
      "decoder.0.norm.weight: 1.0\n",
      "decoder.0.norm.bias: 0.0\n",
      "decoder.0.pwconv1.weight: -1.3060172022960614e-05\n",
      "decoder.0.pwconv1.bias: -0.0013674652436748147\n",
      "decoder.0.grn.gamma: 0.0\n",
      "decoder.0.grn.beta: 0.0\n",
      "decoder.0.pwconv2.weight: -3.248479288231465e-06\n",
      "decoder.0.pwconv2.bias: -0.000629764748737216\n",
      "pred.weight: -0.0004656394012272358\n",
      "pred.bias: 0.0\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_mae.named_parameters():\n",
    "    print(f\"{name}: {param.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downsample_layers.0.0.bias\n",
      "downsample_layers.0.0.weight\n",
      "downsample_layers.0.1.bias\n",
      "downsample_layers.0.1.weight\n",
      "downsample_layers.1.0.bias\n",
      "downsample_layers.1.0.weight\n",
      "downsample_layers.1.1.bias\n",
      "downsample_layers.1.1.weight\n",
      "downsample_layers.2.0.bias\n",
      "downsample_layers.2.0.weight\n",
      "downsample_layers.2.1.bias\n",
      "downsample_layers.2.1.weight\n",
      "downsample_layers.3.0.bias\n",
      "downsample_layers.3.0.weight\n",
      "downsample_layers.3.1.bias\n",
      "downsample_layers.3.1.weight\n",
      "norm.bias\n",
      "norm.weight\n",
      "stages.0.0.grn.beta\n",
      "stages.0.0.grn.gamma\n",
      "stages.0.0.dwconv.bias\n",
      "stages.0.0.dwconv.weight\n",
      "stages.0.0.norm.bias\n",
      "stages.0.0.norm.weight\n",
      "stages.0.0.pwconv1.bias\n",
      "stages.0.0.pwconv1.weight\n",
      "stages.0.0.pwconv2.bias\n",
      "stages.0.0.pwconv2.weight\n",
      "stages.0.1.grn.beta\n",
      "stages.0.1.grn.gamma\n",
      "stages.0.1.dwconv.bias\n",
      "stages.0.1.dwconv.weight\n",
      "stages.0.1.norm.bias\n",
      "stages.0.1.norm.weight\n",
      "stages.0.1.pwconv1.bias\n",
      "stages.0.1.pwconv1.weight\n",
      "stages.0.1.pwconv2.bias\n",
      "stages.0.1.pwconv2.weight\n",
      "stages.0.2.grn.beta\n",
      "stages.0.2.grn.gamma\n",
      "stages.0.2.dwconv.bias\n",
      "stages.0.2.dwconv.weight\n",
      "stages.0.2.norm.bias\n",
      "stages.0.2.norm.weight\n",
      "stages.0.2.pwconv1.bias\n",
      "stages.0.2.pwconv1.weight\n",
      "stages.0.2.pwconv2.bias\n",
      "stages.0.2.pwconv2.weight\n",
      "stages.1.0.grn.beta\n",
      "stages.1.0.grn.gamma\n",
      "stages.1.0.dwconv.bias\n",
      "stages.1.0.dwconv.weight\n",
      "stages.1.0.norm.bias\n",
      "stages.1.0.norm.weight\n",
      "stages.1.0.pwconv1.bias\n",
      "stages.1.0.pwconv1.weight\n",
      "stages.1.0.pwconv2.bias\n",
      "stages.1.0.pwconv2.weight\n",
      "stages.1.1.grn.beta\n",
      "stages.1.1.grn.gamma\n",
      "stages.1.1.dwconv.bias\n",
      "stages.1.1.dwconv.weight\n",
      "stages.1.1.norm.bias\n",
      "stages.1.1.norm.weight\n",
      "stages.1.1.pwconv1.bias\n",
      "stages.1.1.pwconv1.weight\n",
      "stages.1.1.pwconv2.bias\n",
      "stages.1.1.pwconv2.weight\n",
      "stages.1.2.grn.beta\n",
      "stages.1.2.grn.gamma\n",
      "stages.1.2.dwconv.bias\n",
      "stages.1.2.dwconv.weight\n",
      "stages.1.2.norm.bias\n",
      "stages.1.2.norm.weight\n",
      "stages.1.2.pwconv1.bias\n",
      "stages.1.2.pwconv1.weight\n",
      "stages.1.2.pwconv2.bias\n",
      "stages.1.2.pwconv2.weight\n",
      "stages.2.0.grn.beta\n",
      "stages.2.0.grn.gamma\n",
      "stages.2.0.dwconv.bias\n",
      "stages.2.0.dwconv.weight\n",
      "stages.2.0.norm.bias\n",
      "stages.2.0.norm.weight\n",
      "stages.2.0.pwconv1.bias\n",
      "stages.2.0.pwconv1.weight\n",
      "stages.2.0.pwconv2.bias\n",
      "stages.2.0.pwconv2.weight\n",
      "stages.2.1.grn.beta\n",
      "stages.2.1.grn.gamma\n",
      "stages.2.1.dwconv.bias\n",
      "stages.2.1.dwconv.weight\n",
      "stages.2.1.norm.bias\n",
      "stages.2.1.norm.weight\n",
      "stages.2.1.pwconv1.bias\n",
      "stages.2.1.pwconv1.weight\n",
      "stages.2.1.pwconv2.bias\n",
      "stages.2.1.pwconv2.weight\n",
      "stages.2.10.grn.beta\n",
      "stages.2.10.grn.gamma\n",
      "stages.2.10.dwconv.bias\n",
      "stages.2.10.dwconv.weight\n",
      "stages.2.10.norm.bias\n",
      "stages.2.10.norm.weight\n",
      "stages.2.10.pwconv1.bias\n",
      "stages.2.10.pwconv1.weight\n",
      "stages.2.10.pwconv2.bias\n",
      "stages.2.10.pwconv2.weight\n",
      "stages.2.11.grn.beta\n",
      "stages.2.11.grn.gamma\n",
      "stages.2.11.dwconv.bias\n",
      "stages.2.11.dwconv.weight\n",
      "stages.2.11.norm.bias\n",
      "stages.2.11.norm.weight\n",
      "stages.2.11.pwconv1.bias\n",
      "stages.2.11.pwconv1.weight\n",
      "stages.2.11.pwconv2.bias\n",
      "stages.2.11.pwconv2.weight\n",
      "stages.2.12.grn.beta\n",
      "stages.2.12.grn.gamma\n",
      "stages.2.12.dwconv.bias\n",
      "stages.2.12.dwconv.weight\n",
      "stages.2.12.norm.bias\n",
      "stages.2.12.norm.weight\n",
      "stages.2.12.pwconv1.bias\n",
      "stages.2.12.pwconv1.weight\n",
      "stages.2.12.pwconv2.bias\n",
      "stages.2.12.pwconv2.weight\n",
      "stages.2.13.grn.beta\n",
      "stages.2.13.grn.gamma\n",
      "stages.2.13.dwconv.bias\n",
      "stages.2.13.dwconv.weight\n",
      "stages.2.13.norm.bias\n",
      "stages.2.13.norm.weight\n",
      "stages.2.13.pwconv1.bias\n",
      "stages.2.13.pwconv1.weight\n",
      "stages.2.13.pwconv2.bias\n",
      "stages.2.13.pwconv2.weight\n",
      "stages.2.14.grn.beta\n",
      "stages.2.14.grn.gamma\n",
      "stages.2.14.dwconv.bias\n",
      "stages.2.14.dwconv.weight\n",
      "stages.2.14.norm.bias\n",
      "stages.2.14.norm.weight\n",
      "stages.2.14.pwconv1.bias\n",
      "stages.2.14.pwconv1.weight\n",
      "stages.2.14.pwconv2.bias\n",
      "stages.2.14.pwconv2.weight\n",
      "stages.2.15.grn.beta\n",
      "stages.2.15.grn.gamma\n",
      "stages.2.15.dwconv.bias\n",
      "stages.2.15.dwconv.weight\n",
      "stages.2.15.norm.bias\n",
      "stages.2.15.norm.weight\n",
      "stages.2.15.pwconv1.bias\n",
      "stages.2.15.pwconv1.weight\n",
      "stages.2.15.pwconv2.bias\n",
      "stages.2.15.pwconv2.weight\n",
      "stages.2.16.grn.beta\n",
      "stages.2.16.grn.gamma\n",
      "stages.2.16.dwconv.bias\n",
      "stages.2.16.dwconv.weight\n",
      "stages.2.16.norm.bias\n",
      "stages.2.16.norm.weight\n",
      "stages.2.16.pwconv1.bias\n",
      "stages.2.16.pwconv1.weight\n",
      "stages.2.16.pwconv2.bias\n",
      "stages.2.16.pwconv2.weight\n",
      "stages.2.17.grn.beta\n",
      "stages.2.17.grn.gamma\n",
      "stages.2.17.dwconv.bias\n",
      "stages.2.17.dwconv.weight\n",
      "stages.2.17.norm.bias\n",
      "stages.2.17.norm.weight\n",
      "stages.2.17.pwconv1.bias\n",
      "stages.2.17.pwconv1.weight\n",
      "stages.2.17.pwconv2.bias\n",
      "stages.2.17.pwconv2.weight\n",
      "stages.2.18.grn.beta\n",
      "stages.2.18.grn.gamma\n",
      "stages.2.18.dwconv.bias\n",
      "stages.2.18.dwconv.weight\n",
      "stages.2.18.norm.bias\n",
      "stages.2.18.norm.weight\n",
      "stages.2.18.pwconv1.bias\n",
      "stages.2.18.pwconv1.weight\n",
      "stages.2.18.pwconv2.bias\n",
      "stages.2.18.pwconv2.weight\n",
      "stages.2.19.grn.beta\n",
      "stages.2.19.grn.gamma\n",
      "stages.2.19.dwconv.bias\n",
      "stages.2.19.dwconv.weight\n",
      "stages.2.19.norm.bias\n",
      "stages.2.19.norm.weight\n",
      "stages.2.19.pwconv1.bias\n",
      "stages.2.19.pwconv1.weight\n",
      "stages.2.19.pwconv2.bias\n",
      "stages.2.19.pwconv2.weight\n",
      "stages.2.2.grn.beta\n",
      "stages.2.2.grn.gamma\n",
      "stages.2.2.dwconv.bias\n",
      "stages.2.2.dwconv.weight\n",
      "stages.2.2.norm.bias\n",
      "stages.2.2.norm.weight\n",
      "stages.2.2.pwconv1.bias\n",
      "stages.2.2.pwconv1.weight\n",
      "stages.2.2.pwconv2.bias\n",
      "stages.2.2.pwconv2.weight\n",
      "stages.2.20.grn.beta\n",
      "stages.2.20.grn.gamma\n",
      "stages.2.20.dwconv.bias\n",
      "stages.2.20.dwconv.weight\n",
      "stages.2.20.norm.bias\n",
      "stages.2.20.norm.weight\n",
      "stages.2.20.pwconv1.bias\n",
      "stages.2.20.pwconv1.weight\n",
      "stages.2.20.pwconv2.bias\n",
      "stages.2.20.pwconv2.weight\n",
      "stages.2.21.grn.beta\n",
      "stages.2.21.grn.gamma\n",
      "stages.2.21.dwconv.bias\n",
      "stages.2.21.dwconv.weight\n",
      "stages.2.21.norm.bias\n",
      "stages.2.21.norm.weight\n",
      "stages.2.21.pwconv1.bias\n",
      "stages.2.21.pwconv1.weight\n",
      "stages.2.21.pwconv2.bias\n",
      "stages.2.21.pwconv2.weight\n",
      "stages.2.22.grn.beta\n",
      "stages.2.22.grn.gamma\n",
      "stages.2.22.dwconv.bias\n",
      "stages.2.22.dwconv.weight\n",
      "stages.2.22.norm.bias\n",
      "stages.2.22.norm.weight\n",
      "stages.2.22.pwconv1.bias\n",
      "stages.2.22.pwconv1.weight\n",
      "stages.2.22.pwconv2.bias\n",
      "stages.2.22.pwconv2.weight\n",
      "stages.2.23.grn.beta\n",
      "stages.2.23.grn.gamma\n",
      "stages.2.23.dwconv.bias\n",
      "stages.2.23.dwconv.weight\n",
      "stages.2.23.norm.bias\n",
      "stages.2.23.norm.weight\n",
      "stages.2.23.pwconv1.bias\n",
      "stages.2.23.pwconv1.weight\n",
      "stages.2.23.pwconv2.bias\n",
      "stages.2.23.pwconv2.weight\n",
      "stages.2.24.grn.beta\n",
      "stages.2.24.grn.gamma\n",
      "stages.2.24.dwconv.bias\n",
      "stages.2.24.dwconv.weight\n",
      "stages.2.24.norm.bias\n",
      "stages.2.24.norm.weight\n",
      "stages.2.24.pwconv1.bias\n",
      "stages.2.24.pwconv1.weight\n",
      "stages.2.24.pwconv2.bias\n",
      "stages.2.24.pwconv2.weight\n",
      "stages.2.25.grn.beta\n",
      "stages.2.25.grn.gamma\n",
      "stages.2.25.dwconv.bias\n",
      "stages.2.25.dwconv.weight\n",
      "stages.2.25.norm.bias\n",
      "stages.2.25.norm.weight\n",
      "stages.2.25.pwconv1.bias\n",
      "stages.2.25.pwconv1.weight\n",
      "stages.2.25.pwconv2.bias\n",
      "stages.2.25.pwconv2.weight\n",
      "stages.2.26.grn.beta\n",
      "stages.2.26.grn.gamma\n",
      "stages.2.26.dwconv.bias\n",
      "stages.2.26.dwconv.weight\n",
      "stages.2.26.norm.bias\n",
      "stages.2.26.norm.weight\n",
      "stages.2.26.pwconv1.bias\n",
      "stages.2.26.pwconv1.weight\n",
      "stages.2.26.pwconv2.bias\n",
      "stages.2.26.pwconv2.weight\n",
      "stages.2.3.grn.beta\n",
      "stages.2.3.grn.gamma\n",
      "stages.2.3.dwconv.bias\n",
      "stages.2.3.dwconv.weight\n",
      "stages.2.3.norm.bias\n",
      "stages.2.3.norm.weight\n",
      "stages.2.3.pwconv1.bias\n",
      "stages.2.3.pwconv1.weight\n",
      "stages.2.3.pwconv2.bias\n",
      "stages.2.3.pwconv2.weight\n",
      "stages.2.4.grn.beta\n",
      "stages.2.4.grn.gamma\n",
      "stages.2.4.dwconv.bias\n",
      "stages.2.4.dwconv.weight\n",
      "stages.2.4.norm.bias\n",
      "stages.2.4.norm.weight\n",
      "stages.2.4.pwconv1.bias\n",
      "stages.2.4.pwconv1.weight\n",
      "stages.2.4.pwconv2.bias\n",
      "stages.2.4.pwconv2.weight\n",
      "stages.2.5.grn.beta\n",
      "stages.2.5.grn.gamma\n",
      "stages.2.5.dwconv.bias\n",
      "stages.2.5.dwconv.weight\n",
      "stages.2.5.norm.bias\n",
      "stages.2.5.norm.weight\n",
      "stages.2.5.pwconv1.bias\n",
      "stages.2.5.pwconv1.weight\n",
      "stages.2.5.pwconv2.bias\n",
      "stages.2.5.pwconv2.weight\n",
      "stages.2.6.grn.beta\n",
      "stages.2.6.grn.gamma\n",
      "stages.2.6.dwconv.bias\n",
      "stages.2.6.dwconv.weight\n",
      "stages.2.6.norm.bias\n",
      "stages.2.6.norm.weight\n",
      "stages.2.6.pwconv1.bias\n",
      "stages.2.6.pwconv1.weight\n",
      "stages.2.6.pwconv2.bias\n",
      "stages.2.6.pwconv2.weight\n",
      "stages.2.7.grn.beta\n",
      "stages.2.7.grn.gamma\n",
      "stages.2.7.dwconv.bias\n",
      "stages.2.7.dwconv.weight\n",
      "stages.2.7.norm.bias\n",
      "stages.2.7.norm.weight\n",
      "stages.2.7.pwconv1.bias\n",
      "stages.2.7.pwconv1.weight\n",
      "stages.2.7.pwconv2.bias\n",
      "stages.2.7.pwconv2.weight\n",
      "stages.2.8.grn.beta\n",
      "stages.2.8.grn.gamma\n",
      "stages.2.8.dwconv.bias\n",
      "stages.2.8.dwconv.weight\n",
      "stages.2.8.norm.bias\n",
      "stages.2.8.norm.weight\n",
      "stages.2.8.pwconv1.bias\n",
      "stages.2.8.pwconv1.weight\n",
      "stages.2.8.pwconv2.bias\n",
      "stages.2.8.pwconv2.weight\n",
      "stages.2.9.grn.beta\n",
      "stages.2.9.grn.gamma\n",
      "stages.2.9.dwconv.bias\n",
      "stages.2.9.dwconv.weight\n",
      "stages.2.9.norm.bias\n",
      "stages.2.9.norm.weight\n",
      "stages.2.9.pwconv1.bias\n",
      "stages.2.9.pwconv1.weight\n",
      "stages.2.9.pwconv2.bias\n",
      "stages.2.9.pwconv2.weight\n",
      "stages.3.0.grn.beta\n",
      "stages.3.0.grn.gamma\n",
      "stages.3.0.dwconv.bias\n",
      "stages.3.0.dwconv.weight\n",
      "stages.3.0.norm.bias\n",
      "stages.3.0.norm.weight\n",
      "stages.3.0.pwconv1.bias\n",
      "stages.3.0.pwconv1.weight\n",
      "stages.3.0.pwconv2.bias\n",
      "stages.3.0.pwconv2.weight\n",
      "stages.3.1.grn.beta\n",
      "stages.3.1.grn.gamma\n",
      "stages.3.1.dwconv.bias\n",
      "stages.3.1.dwconv.weight\n",
      "stages.3.1.norm.bias\n",
      "stages.3.1.norm.weight\n",
      "stages.3.1.pwconv1.bias\n",
      "stages.3.1.pwconv1.weight\n",
      "stages.3.1.pwconv2.bias\n",
      "stages.3.1.pwconv2.weight\n",
      "stages.3.2.grn.beta\n",
      "stages.3.2.grn.gamma\n",
      "stages.3.2.dwconv.bias\n",
      "stages.3.2.dwconv.weight\n",
      "stages.3.2.norm.bias\n",
      "stages.3.2.norm.weight\n",
      "stages.3.2.pwconv1.bias\n",
      "stages.3.2.pwconv1.weight\n",
      "stages.3.2.pwconv2.bias\n",
      "stages.3.2.pwconv2.weight\n"
     ]
    }
   ],
   "source": [
    "for key in checkpoint_model.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoints(epoch, model, optimizer, stage):\n",
    "    checkpoint_path = f\"checkpoints/ConvNeXtV2/{stage}\"\n",
    "    \n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(f\"Load checkpoint from {checkpoint_path}\")\n",
    "        checkpoint = torch.load(os.path.join(checkpoint_path, f\"checkpoint_{epoch}.pth\"))\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(f\"Loaded checkpoint from epoch {epoch}\")\n",
    "\n",
    "def save_checkpoints(epoch, model, optimizer, stage):\n",
    "    checkpoint_path = f\"checkpoints/ConvNeXtV2/{stage}\"\n",
    "    \n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    \n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }, checkpoint_path + f\"/checkpoint_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrain Imagenet1k\n",
    "import torch.cuda\n",
    "\n",
    "\n",
    "pretrain_epoch = 1600\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "start_epoch = 0\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "if start_epoch:\n",
    "    load_checkpoints(start_epoch, model_mae, optimizer, stage=\"imagenet\")\n",
    "\n",
    "for epoch in range(start_epoch, pretrain_epoch):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1, pretrain_epoch,localtime))\n",
    "    print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1, pretrain_epoch,localtime)))\n",
    "\n",
    "    folder_name = os.path.join(\"see_image\", \"warm\")\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for batch in tqdm(imagenet_loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        img, label = batch\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "\n",
    "        loss, pred, mask = model_mae(img)\n",
    "        loss = mse_loss(pred, img)    \n",
    "\n",
    "        image = pred[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "        img_np = img[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "        img_np = (img_np * 255).astype(np.uint8)\n",
    "        pred_np = (image * 255).astype(np.uint8)\n",
    "\n",
    "        cv2.imshow(\"pred img\", pred_np)\n",
    "        cv2.waitKey(1)\n",
    "        cv2.imshow(\"targe img\", img_np)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch{epoch+1} loss : \\n pretrain loss : {epoch_loss/len(train_loader)}')\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_checkpoints(epoch+1, model=model_mae, optimizer=optimizer, stage=\"imagenet\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrain fcmae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetune mae on oasis dataset\n",
    "import torch.cuda\n",
    "\n",
    "\n",
    "pretrain_epoch = 1600\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "start_epoch = 0\n",
    "\n",
    "mse_loss = nn.MSELoss()\n",
    "\n",
    "if start_epoch:\n",
    "    load_checkpoints(start_epoch, model_mae, optimizer, stage=\"pretrain\")\n",
    "\n",
    "for epoch in range(start_epoch, pretrain_epoch):\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1, pretrain_epoch,localtime))\n",
    "    print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1, pretrain_epoch,localtime)))\n",
    "\n",
    "    folder_name = os.path.join(\"see_image\", \"warm\")\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        torch.cuda.empty_cache()\n",
    "        img, label = batch\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "\n",
    "        loss, pred, mask = model_mae(img)\n",
    "        loss = mse_loss(pred, img)    \n",
    "\n",
    "        image = pred[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "        img_np = img[0].cpu().detach().numpy().transpose(1, 2, 0)\n",
    "        img_np = (img_np * 255).astype(np.uint8)\n",
    "        pred_np = (image * 255).astype(np.uint8)\n",
    "\n",
    "        cv2.imshow(\"pred img\", pred_np)\n",
    "        cv2.waitKey(1)\n",
    "        cv2.imshow(\"targe img\", img_np)\n",
    "        cv2.waitKey(1)\n",
    "\n",
    "        \n",
    "        epoch_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch{epoch+1} loss : \\n pretrain loss : {epoch_loss/len(train_loader)}')\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_checkpoints(epoch+1, model=model_mae, optimizer=optimizer, stage=\"pretrain\")\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_mae = None\n",
    "torch.cuda.empty_cache()\n",
    "param_groups = optim_factory.add_weight_decay(model_autoencoder, 0.05)\n",
    "optimizer = torch.optim.AdamW(param_groups, lr=1.5e-4, betas=(0.9, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load warm model weight to semi-supervised model\n",
    "from Model.ConvNeXtV2.utils_param import remap_checkpoint_keys\n",
    "\n",
    "def load_model(source_model, target_model):\n",
    "    \n",
    "    checkpoint_model = source_model.state_dict()\n",
    "\n",
    "    state_dict = target_model.state_dict()\n",
    "    for k in ['head.weight', 'head.bias']:\n",
    "        if k in checkpoint_model and checkpoint_model[k].shape != state_dict[k].shape:\n",
    "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "            del checkpoint_model[k]\n",
    "        \n",
    "\n",
    "    # remove decoder weights\n",
    "    checkpoint_model_keys = list(checkpoint_model.keys())\n",
    "    for k in checkpoint_model_keys:\n",
    "        if 'decoder' in k or 'mask_token'in k or \\\n",
    "           'proj' in k or 'pred' in k:\n",
    "            print(f\"Removing key {k} from pretrained checkpoint\")\n",
    "            del checkpoint_model[k]\n",
    "\n",
    "    checkpoint_model = remap_checkpoint_keys(checkpoint_model)\n",
    "    target_model.load_state_dict(checkpoint_model)\n",
    "\n",
    "    return target_model\n",
    "\n",
    "#model_autoencoder = load_model(model_mae, model_autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/25 --- < Starting Time : Fri Dec 20 17:02:21 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [37:52<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch1 loss : \n",
      " pretrain loss : 0.5624855756759644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.73it/s]\n",
      "/home/lab308/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7190\n",
      "Recall: 0.7833\n",
      "F1 Score: 0.7488\n",
      "Accuracy: 0.7833\n",
      "Test loss: 0.5205876421194553\n",
      "Epoch: 2/25 --- < Starting Time : Fri Dec 20 17:43:21 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:30<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch2 loss : \n",
      " pretrain loss : 0.4728028178215027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:03<00:00, 11.76it/s]\n",
      "/home/lab308/.local/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7620\n",
      "Recall: 0.7933\n",
      "F1 Score: 0.7758\n",
      "Accuracy: 0.7933\n",
      "Test loss: 0.4512654781216141\n",
      "Epoch: 3/25 --- < Starting Time : Fri Dec 20 18:24:59 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:28<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch3 loss : \n",
      " pretrain loss : 0.42120638489723206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.8148\n",
      "Recall: 0.8294\n",
      "F1 Score: 0.8161\n",
      "Accuracy: 0.8294\n",
      "Test loss: 0.38422484600117923\n",
      "Epoch: 4/25 --- < Starting Time : Fri Dec 20 19:06:37 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:28<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch4 loss : \n",
      " pretrain loss : 0.30743837356567383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9092\n",
      "Recall: 0.9108\n",
      "F1 Score: 0.9045\n",
      "Accuracy: 0.9108\n",
      "Test loss: 0.24211680069402947\n",
      "Epoch: 5/25 --- < Starting Time : Fri Dec 20 19:48:14 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:27<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch5 loss : \n",
      " pretrain loss : 0.16052958369255066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9537\n",
      "Recall: 0.9531\n",
      "F1 Score: 0.9524\n",
      "Accuracy: 0.9531\n",
      "Test loss: 0.12467066031977247\n",
      "Epoch: 6/25 --- < Starting Time : Fri Dec 20 20:29:49 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:24<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch6 loss : \n",
      " pretrain loss : 0.08539946377277374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:03<00:00, 11.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9804\n",
      "Recall: 0.9803\n",
      "F1 Score: 0.9803\n",
      "Accuracy: 0.9803\n",
      "Test loss: 0.05434288508276807\n",
      "Epoch: 7/25 --- < Starting Time : Fri Dec 20 21:11:19 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:20<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch7 loss : \n",
      " pretrain loss : 0.0574377179145813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9780\n",
      "Recall: 0.9781\n",
      "F1 Score: 0.9777\n",
      "Accuracy: 0.9781\n",
      "Test loss: 0.06759797322807068\n",
      "Epoch: 8/25 --- < Starting Time : Fri Dec 20 21:52:49 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:23<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch8 loss : \n",
      " pretrain loss : 0.04155855253338814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:03<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9872\n",
      "Recall: 0.9872\n",
      "F1 Score: 0.9872\n",
      "Accuracy: 0.9872\n",
      "Test loss: 0.038824917398795865\n",
      "Epoch: 9/25 --- < Starting Time : Fri Dec 20 22:34:20 2024 >\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:26<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch9 loss : \n",
      " pretrain loss : 0.03407704830169678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9735\n",
      "Recall: 0.9703\n",
      "F1 Score: 0.9710\n",
      "Accuracy: 0.9703\n",
      "Test loss: 0.08971495766016924\n",
      "Epoch: 10/25 --- < Starting Time : Fri Dec 20 23:15:55 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:27<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch10 loss : \n",
      " pretrain loss : 0.02813187800347805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9843\n",
      "Recall: 0.9839\n",
      "F1 Score: 0.9838\n",
      "Accuracy: 0.9839\n",
      "Test loss: 0.054336440542615085\n",
      "Epoch: 11/25 --- < Starting Time : Fri Dec 20 23:57:31 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:27<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch11 loss : \n",
      " pretrain loss : 0.026227395981550217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9881\n",
      "Recall: 0.9877\n",
      "F1 Score: 0.9878\n",
      "Accuracy: 0.9877\n",
      "Test loss: 0.040719108414325515\n",
      "Epoch: 12/25 --- < Starting Time : Sat Dec 21 00:39:06 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:30<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch12 loss : \n",
      " pretrain loss : 0.023013759404420853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:06<00:00, 11.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9891\n",
      "Recall: 0.9866\n",
      "F1 Score: 0.9874\n",
      "Accuracy: 0.9866\n",
      "Test loss: 0.04375158126526491\n",
      "Epoch: 13/25 --- < Starting Time : Sat Dec 21 01:20:46 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:29<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch13 loss : \n",
      " pretrain loss : 0.02165011130273342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:03<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9936\n",
      "Recall: 0.9935\n",
      "F1 Score: 0.9935\n",
      "Accuracy: 0.9935\n",
      "Test loss: 0.020821082152135007\n",
      "Epoch: 14/25 --- < Starting Time : Sat Dec 21 02:02:23 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch14 loss : \n",
      " pretrain loss : 0.02007344737648964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9928\n",
      "Recall: 0.9928\n",
      "F1 Score: 0.9928\n",
      "Accuracy: 0.9928\n",
      "Test loss: 0.02632679514144273\n",
      "Epoch: 15/25 --- < Starting Time : Sat Dec 21 02:44:04 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch15 loss : \n",
      " pretrain loss : 0.019127612933516502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9909\n",
      "Recall: 0.9909\n",
      "F1 Score: 0.9909\n",
      "Accuracy: 0.9909\n",
      "Test loss: 0.029798990421152593\n",
      "Epoch: 16/25 --- < Starting Time : Sat Dec 21 03:25:43 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:30<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch16 loss : \n",
      " pretrain loss : 0.017667638137936592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:06<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9941\n",
      "Recall: 0.9940\n",
      "F1 Score: 0.9940\n",
      "Accuracy: 0.9940\n",
      "Test loss: 0.015920898362790543\n",
      "Epoch: 17/25 --- < Starting Time : Sat Dec 21 04:07:24 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:33<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch17 loss : \n",
      " pretrain loss : 0.0171979870647192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:03<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9940\n",
      "Recall: 0.9939\n",
      "F1 Score: 0.9939\n",
      "Accuracy: 0.9939\n",
      "Test loss: 0.02166975298532725\n",
      "Epoch: 18/25 --- < Starting Time : Sat Dec 21 04:49:05 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch18 loss : \n",
      " pretrain loss : 0.0161428302526474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9962\n",
      "Recall: 0.9962\n",
      "F1 Score: 0.9962\n",
      "Accuracy: 0.9962\n",
      "Test loss: 0.011463783015853797\n",
      "Epoch: 19/25 --- < Starting Time : Sat Dec 21 05:30:46 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:30<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch19 loss : \n",
      " pretrain loss : 0.01737247034907341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9957\n",
      "Recall: 0.9957\n",
      "F1 Score: 0.9957\n",
      "Accuracy: 0.9957\n",
      "Test loss: 0.013433803570734308\n",
      "Epoch: 20/25 --- < Starting Time : Sat Dec 21 06:12:24 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:27<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch20 loss : \n",
      " pretrain loss : 0.01596021093428135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9914\n",
      "Recall: 0.9913\n",
      "F1 Score: 0.9913\n",
      "Accuracy: 0.9913\n",
      "Test loss: 0.03154834559909567\n",
      "Epoch: 21/25 --- < Starting Time : Sat Dec 21 06:54:00 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:32<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch21 loss : \n",
      " pretrain loss : 0.016267351806163788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:03<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9948\n",
      "Recall: 0.9947\n",
      "F1 Score: 0.9947\n",
      "Accuracy: 0.9947\n",
      "Test loss: 0.015653679306171016\n",
      "Epoch: 22/25 --- < Starting Time : Sat Dec 21 07:35:40 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch22 loss : \n",
      " pretrain loss : 0.014237558469176292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9968\n",
      "Recall: 0.9968\n",
      "F1 Score: 0.9968\n",
      "Accuracy: 0.9968\n",
      "Test loss: 0.011285787459334572\n",
      "Epoch: 23/25 --- < Starting Time : Sat Dec 21 08:17:20 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:28<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch23 loss : \n",
      " pretrain loss : 0.014600737020373344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9969\n",
      "Recall: 0.9969\n",
      "F1 Score: 0.9969\n",
      "Accuracy: 0.9969\n",
      "Test loss: 0.00856858497913011\n",
      "Epoch: 24/25 --- < Starting Time : Sat Dec 21 08:58:57 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:31<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch24 loss : \n",
      " pretrain loss : 0.014716844074428082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:05<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9943\n",
      "Recall: 0.9943\n",
      "F1 Score: 0.9943\n",
      "Accuracy: 0.9943\n",
      "Test loss: 0.023546327718000432\n",
      "Epoch: 25/25 --- < Starting Time : Sat Dec 21 09:40:37 2024 >\n",
      "-------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8644/8644 [38:26<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch25 loss : \n",
      " pretrain loss : 0.013754679821431637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:04<00:00, 11.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9978\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9978\n",
      "Accuracy: 0.9978\n",
      "Test loss: 0.0062979711272184765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# finetune classification\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "model_mae = None\n",
    "torch.cuda.empty_cache()\n",
    "pretrain_epoch = 25\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "start_epoch = 0\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "\n",
    "if start_epoch:\n",
    "    load_checkpoints(start_epoch-1, model_mae, optimizer, stage=\"finetune\")\n",
    "\n",
    "for epoch in range(start_epoch, pretrain_epoch):\n",
    "    torch.cuda.empty_cache()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1, pretrain_epoch,localtime))\n",
    "    print('-' * len('Epoch: {}/{} --- < Starting Time : {} >'.format(epoch + 1, pretrain_epoch,localtime)))\n",
    "\n",
    "    folder_name = os.path.join(\"see_image\", \"warm\")\n",
    "    os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    #model_mae.eval()\n",
    "    model_autoencoder.train()\n",
    "    \n",
    "    \n",
    "    for batch in tqdm(finetune_loader):\n",
    "        img, label = batch\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "\n",
    "        logits = model_autoencoder(img)\n",
    "        loss = ce_loss(logits, label)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss\n",
    "    epoch_loss = epoch_loss / len(finetune_loader)\n",
    "        \n",
    "    print(f'Epoch{epoch+1} loss : \\n pretrain loss : {epoch_loss}')\n",
    "    \n",
    "    with open(\"Convnextv2_train.txt\", 'a+') as f:\n",
    "        f.write(f\"{epoch_loss}\\n\")\n",
    "        \n",
    "    #validation\n",
    "    test_loss = 0\n",
    "    model_autoencoder.eval()\n",
    "\n",
    "    # Initialize lists to store true labels and predictions\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader):\n",
    "            img, label = batch\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            #image_features = model.encode_image(img)\n",
    "            #text_features = model.encode_text(clip.tokenize(cathegories).to(device))\n",
    "\n",
    "            logits = model_autoencoder(img)\n",
    "            #probs = logits_img.softmax(dim=-1).cpu().numpy()\n",
    "            loss = ce_loss(logits, label)\n",
    "\n",
    "            \n",
    "            # Store the true labels and predictions\n",
    "            preds = logits.argmax(dim=1).cpu().numpy()\n",
    "            all_labels.extend(label.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "            test_loss += loss.item()\n",
    "    test_loss = test_loss / len(val_loader)\n",
    "    with open(\"Convnextv2_val.txt\",  \"a+\") as f:\n",
    "        f.write(f\"{test_loss}\\n\")\n",
    "            \n",
    "    # Calculate precision, recall, F1 score, and accuracy\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    print(\"Test loss:\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2161/2161 [03:03<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9978\n",
      "Recall: 0.9978\n",
      "F1 Score: 0.9978\n",
      "Accuracy: 0.9978\n",
      "Test loss: 1.664435512793716e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "test_loss = 0\n",
    "model_autoencoder.eval()\n",
    "\n",
    "# Initialize lists to store true labels and predictions\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_loader):\n",
    "        img, label = batch\n",
    "        img, label = img.to(device), label.to(device)\n",
    "\n",
    "        #image_features = model.encode_image(img)\n",
    "        #text_features = model.encode_text(clip.tokenize(cathegories).to(device))\n",
    "\n",
    "        logits = model_autoencoder(img)\n",
    "        #probs = logits_img.softmax(dim=-1).cpu().numpy()\n",
    "        loss = ce_loss(logits, label)\n",
    "\n",
    "        test_loss += loss\n",
    "        # Store the true labels and predictions\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        all_labels.extend(label.cpu().numpy())\n",
    "        all_preds.extend(preds)\n",
    "        \n",
    "# Calculate precision, recall, F1 score, and accuracy\n",
    "precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"Test loss:\", loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convnextv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
